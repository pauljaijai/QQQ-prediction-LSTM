{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd1g5vfPP6ID"
      },
      "outputs": [],
      "source": [
        "#  source :# https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_3xXg-wQB4i",
        "outputId": "5b9cce56-8e61-4592-8da4-554f0b0402dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: yahoo_fin in /usr/local/lib/python3.7/dist-packages (0.8.9.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.7/dist-packages (4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: config in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.25.11)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (6.0.8)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (0.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.7/dist-packages (from datetime) (5.4.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser->yahoo_fin) (1.0.0)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.22.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.19.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.1.11)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.0.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.0.2)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (1.4.3)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.63.0)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (10.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo_fin) (4.6.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow pandas numpy matplotlib yahoo_fin sklearn datetime requests config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gH_PrwPQSVF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import requests, json\n",
        "from config import *\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diYTzP3twnzO"
      },
      "outputs": [],
      "source": [
        "API_KEY = ''\n",
        "SECRETE_KEY=''\n",
        "BASE_URL ='https://paper-api.alpaca.markets'\n",
        "ACCOUNT_URL='{}/v2/account'.format(BASE_URL)\n",
        "ORDERS_URL = '{}/v2/orders'.format(BASE_URL)\n",
        "POSITION_URL = '{}/v2/position'.format(BASE_URL)\n",
        "POSITIONS_URL= '{}/v2/positions'.format(BASE_URL)\n",
        "ASSESTS_URL = '{}/v2/assets/QQQ'.format(BASE_URL)\n",
        "HEADERS ={'APCA-API-KEY-ID':API_KEY ,  'APCA-API-SECRET-KEY':SECRETE_KEY}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6expxivF-qV"
      },
      "outputs": [],
      "source": [
        "def get_final_df(model, data):\n",
        "    \n",
        "    \n",
        "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
        "   \n",
        "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_test = data[\"y_test\"]\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    if SCALE:\n",
        "        y_test = np.squeeze(data[\"column_scaler\"][\"close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "        y_pred = np.squeeze(data[\"column_scaler\"][\"close\"].inverse_transform(y_pred))\n",
        "    test_df = data[\"test_df\"]\n",
        "    \n",
        "    test_df[f\"close_{LOOKUP_STEP}\"] = y_pred\n",
        "    \n",
        "    test_df[f\"true_close_{LOOKUP_STEP}\"] = y_test\n",
        "    \n",
        "    test_df.sort_index(inplace=True)\n",
        "    final_df = test_df\n",
        "    \n",
        "   \n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQrwM7nJQZj3"
      },
      "outputs": [],
      "source": [
        "def shuffle_in_unison(a, b):\n",
        "    \n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(a)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(b)\n",
        "\n",
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
        "                test_size=0.2, feature_columns= ['close', 'volume', 'open', 'high', 'low']):\n",
        "    if isinstance(ticker, str):\n",
        "       \n",
        "        df_QQQ = si.get_data(ticker , start_date='01/01/1999'  )\n",
        "        df_FTSE = si.get_data('^FTSE' , start_date='01/05/2000' )\n",
        "        df_FTSE.drop(['adjclose','ticker'],1,inplace=True)\n",
        "        df_QQQ.drop(['adjclose','ticker'],1,inplace=True)\n",
        "        df_FTSE.rename({'open': 'FTSE_open', 'high': 'FTSE_high' , 'low': 'FTSE_low' , 'close':'FTSE_close' , 'volume':'FTSE_volume'}, axis=1, inplace=True)\n",
        "       \n",
        "        df = pd.concat([df_QQQ, df_FTSE], axis=1 ) \n",
        "        df= df_QQQ\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "       \n",
        "        df = ticker\n",
        "    else:\n",
        "      print('error')     \n",
        "   \n",
        "    result = {}\n",
        "    \n",
        "    result['df'] = df.copy()\n",
        "    \n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "\n",
        "    if \"date\" not in df.columns:\n",
        "        df[\"date\"] = df.index\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        \n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "       \n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "   \n",
        "    df['future'] = df['close'].shift(-lookup_step)\n",
        " \n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    \n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "  \n",
        "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
        "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
        " \n",
        "    result['last_sequence'] = last_sequence\n",
        "    \n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        " \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    if split_by_date:\n",
        "      \n",
        "        train_samples = int((1 - test_size) * len(X))\n",
        "        result[\"X_train\"] = X[:train_samples]\n",
        "        result[\"y_train\"] = y[:train_samples]\n",
        "        result[\"X_test\"]  = X[train_samples:]\n",
        "        result[\"y_test\"]  = y[train_samples:]\n",
        "        if shuffle:\n",
        "            \n",
        "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
        "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
        "    else:    \n",
        "       \n",
        "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
        "                                                                                test_size=test_size, shuffle=shuffle)\n",
        "    \n",
        "    dates = result[\"X_test\"][:, -1, -1]\n",
        "    \n",
        "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
        "\n",
        "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
        "    \n",
        "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCdID5WWQlqu"
      },
      "outputs": [],
      "source": [
        "def create_model(sequence_length, n_features, units, cell, n_layers, dropout,\n",
        "                loss, optimizer):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "              model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
        "        elif i == n_layers - 1:\n",
        "            \n",
        "              model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "              model.add(cell(units, return_sequences=True))\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"relu\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6UXKNETF_5M"
      },
      "outputs": [],
      "source": [
        "def predict(model, data):\n",
        "\n",
        "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
        "\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "\n",
        "    prediction = model.predict(last_sequence)\n",
        "    \n",
        "    if SCALE:\n",
        "        predicted_price = data[\"column_scaler\"][\"close\"].inverse_transform(prediction)[0][0]\n",
        "    else:\n",
        "        predicted_price = prediction[0][0]\n",
        "    return predicted_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbQFufxrQWfP"
      },
      "outputs": [],
      "source": [
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X6DhPg1Qqto",
        "outputId": "89e4dab0-8203-437e-cebb-a711e8118803"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "N_STEPS = 50\n",
        "\n",
        "LOOKUP_STEP = 1\n",
        "\n",
        "SCALE = True\n",
        "scale_str = f\"sc-{int(SCALE)}\"\n",
        "\n",
        "SHUFFLE = True\n",
        "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
        "\n",
        "SPLIT_BY_DATE = False\n",
        "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
        "\n",
        "TEST_SIZE = 0.1\n",
        "\n",
        "FEATURE_COLUMNS = ['close', 'volume', 'open', 'high', 'low' , 'FTSE_open' , 'FTSE_high' , 'FTSE_low', 'FTSE_close', 'FTSE_volume' ]\n",
        "\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "N_LAYERS = 3\n",
        "\n",
        "CELL = LSTM\n",
        "\n",
        "UNITS = 256\n",
        "\n",
        "DROPOUT = 0.3\n",
        "\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(lr=0.0005 , decay= 1e-5)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 300\n",
        "\n",
        "ticker = \"QQQ\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "\n",
        "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
        "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aK7d4_IQzk0",
        "outputId": "53304e55-a321-42fe-98fc-33e802efaa4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0233\n",
            "Epoch 1: val_loss improved from inf to 0.00017, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 103s 1s/step - loss: 0.0014 - mean_absolute_error: 0.0233 - val_loss: 1.6821e-04 - val_mean_absolute_error: 0.0124\n",
            "Epoch 2/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 3.3762e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 2: val_loss improved from 0.00017 to 0.00005, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 82s 1s/step - loss: 3.3762e-04 - mean_absolute_error: 0.0151 - val_loss: 5.4673e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 3/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 3.2174e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 3: val_loss did not improve from 0.00005\n",
            "81/81 [==============================] - 80s 982ms/step - loss: 3.2174e-04 - mean_absolute_error: 0.0147 - val_loss: 5.9352e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 4/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 3.4560e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 4: val_loss did not improve from 0.00005\n",
            "81/81 [==============================] - 79s 973ms/step - loss: 3.4560e-04 - mean_absolute_error: 0.0154 - val_loss: 1.0120e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 5/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.7718e-04 - mean_absolute_error: 0.0138\n",
            "Epoch 5: val_loss did not improve from 0.00005\n",
            "81/81 [==============================] - 78s 965ms/step - loss: 2.7718e-04 - mean_absolute_error: 0.0138 - val_loss: 7.8699e-05 - val_mean_absolute_error: 0.0077\n",
            "Epoch 6/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 3.3292e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 6: val_loss did not improve from 0.00005\n",
            "81/81 [==============================] - 79s 972ms/step - loss: 3.3292e-04 - mean_absolute_error: 0.0151 - val_loss: 7.7310e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 7/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.6063e-04 - mean_absolute_error: 0.0131\n",
            "Epoch 7: val_loss did not improve from 0.00005\n",
            "81/81 [==============================] - 79s 971ms/step - loss: 2.6063e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4651e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 8/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 3.0976e-04 - mean_absolute_error: 0.0141\n",
            "Epoch 8: val_loss did not improve from 0.00005\n",
            "81/81 [==============================] - 78s 968ms/step - loss: 3.0976e-04 - mean_absolute_error: 0.0141 - val_loss: 1.8138e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 9/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.7066e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 9: val_loss improved from 0.00005 to 0.00004, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 2.7066e-04 - mean_absolute_error: 0.0136 - val_loss: 3.9805e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 10/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.5029e-04 - mean_absolute_error: 0.0130\n",
            "Epoch 10: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 79s 980ms/step - loss: 2.5029e-04 - mean_absolute_error: 0.0130 - val_loss: 4.0804e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 11/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.4925e-04 - mean_absolute_error: 0.0130\n",
            "Epoch 11: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 2.4925e-04 - mean_absolute_error: 0.0130 - val_loss: 5.4167e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 12/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.9498e-04 - mean_absolute_error: 0.0114\n",
            "Epoch 12: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 79s 975ms/step - loss: 1.9498e-04 - mean_absolute_error: 0.0114 - val_loss: 6.9185e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 13/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.2250e-04 - mean_absolute_error: 0.0119\n",
            "Epoch 13: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 79s 974ms/step - loss: 2.2250e-04 - mean_absolute_error: 0.0119 - val_loss: 5.9427e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 14/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.9096e-04 - mean_absolute_error: 0.0115\n",
            "Epoch 14: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 80s 988ms/step - loss: 1.9096e-04 - mean_absolute_error: 0.0115 - val_loss: 6.5341e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 15/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.1567e-04 - mean_absolute_error: 0.0117\n",
            "Epoch 15: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 2.1567e-04 - mean_absolute_error: 0.0117 - val_loss: 1.8696e-04 - val_mean_absolute_error: 0.0117\n",
            "Epoch 16/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.9423e-04 - mean_absolute_error: 0.0111\n",
            "Epoch 16: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 79s 973ms/step - loss: 1.9423e-04 - mean_absolute_error: 0.0111 - val_loss: 7.7659e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 17/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.8162e-04 - mean_absolute_error: 0.0111\n",
            "Epoch 17: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 1.8162e-04 - mean_absolute_error: 0.0111 - val_loss: 4.8398e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 18/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.3958e-04 - mean_absolute_error: 0.0126\n",
            "Epoch 18: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 81s 998ms/step - loss: 2.3958e-04 - mean_absolute_error: 0.0126 - val_loss: 1.4387e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 19/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.1258e-04 - mean_absolute_error: 0.0120\n",
            "Epoch 19: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 80s 986ms/step - loss: 2.1258e-04 - mean_absolute_error: 0.0120 - val_loss: 4.8822e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 20/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.2274e-04 - mean_absolute_error: 0.0119\n",
            "Epoch 20: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 80s 990ms/step - loss: 2.2274e-04 - mean_absolute_error: 0.0119 - val_loss: 4.7482e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 21/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.7942e-04 - mean_absolute_error: 0.0107\n",
            "Epoch 21: val_loss improved from 0.00004 to 0.00004, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 81s 994ms/step - loss: 1.7942e-04 - mean_absolute_error: 0.0107 - val_loss: 3.8748e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 22/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 2.2111e-04 - mean_absolute_error: 0.0123\n",
            "Epoch 22: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 81s 996ms/step - loss: 2.2111e-04 - mean_absolute_error: 0.0123 - val_loss: 2.7527e-04 - val_mean_absolute_error: 0.0168\n",
            "Epoch 23/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.8815e-04 - mean_absolute_error: 0.0114\n",
            "Epoch 23: val_loss did not improve from 0.00004\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 1.8815e-04 - mean_absolute_error: 0.0114 - val_loss: 4.0277e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 24/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.8063e-04 - mean_absolute_error: 0.0109\n",
            "Epoch 24: val_loss improved from 0.00004 to 0.00004, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.8063e-04 - mean_absolute_error: 0.0109 - val_loss: 3.5218e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 25/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.6082e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 25: val_loss improved from 0.00004 to 0.00003, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 80s 993ms/step - loss: 1.6082e-04 - mean_absolute_error: 0.0101 - val_loss: 3.4499e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 26/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.9983e-04 - mean_absolute_error: 0.0113\n",
            "Epoch 26: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 79s 977ms/step - loss: 1.9983e-04 - mean_absolute_error: 0.0113 - val_loss: 6.4974e-05 - val_mean_absolute_error: 0.0074\n",
            "Epoch 27/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.6466e-04 - mean_absolute_error: 0.0105\n",
            "Epoch 27: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 1.6466e-04 - mean_absolute_error: 0.0105 - val_loss: 1.4485e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 28/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.7563e-04 - mean_absolute_error: 0.0109\n",
            "Epoch 28: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 79s 979ms/step - loss: 1.7563e-04 - mean_absolute_error: 0.0109 - val_loss: 5.8843e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 29/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5313e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 29: val_loss improved from 0.00003 to 0.00003, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.5313e-04 - mean_absolute_error: 0.0100 - val_loss: 3.4016e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 30/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5263e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 30: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 1.5263e-04 - mean_absolute_error: 0.0101 - val_loss: 6.0230e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 31/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.9338e-04 - mean_absolute_error: 0.0111\n",
            "Epoch 31: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 1.9338e-04 - mean_absolute_error: 0.0111 - val_loss: 8.9320e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 32/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.7732e-04 - mean_absolute_error: 0.0110\n",
            "Epoch 32: val_loss improved from 0.00003 to 0.00003, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 80s 986ms/step - loss: 1.7732e-04 - mean_absolute_error: 0.0110 - val_loss: 2.9844e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 33/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.7129e-04 - mean_absolute_error: 0.0106\n",
            "Epoch 33: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.7129e-04 - mean_absolute_error: 0.0106 - val_loss: 3.3196e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 34/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5473e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 34: val_loss improved from 0.00003 to 0.00003, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.5473e-04 - mean_absolute_error: 0.0101 - val_loss: 2.7590e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 35/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4500e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 35: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 1000ms/step - loss: 1.4500e-04 - mean_absolute_error: 0.0099 - val_loss: 3.2273e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 36/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3965e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 36: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 999ms/step - loss: 1.3965e-04 - mean_absolute_error: 0.0098 - val_loss: 3.3069e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 37/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.7258e-04 - mean_absolute_error: 0.0106\n",
            "Epoch 37: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 991ms/step - loss: 1.7258e-04 - mean_absolute_error: 0.0106 - val_loss: 3.8591e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 38/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4313e-04 - mean_absolute_error: 0.0102\n",
            "Epoch 38: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 992ms/step - loss: 1.4313e-04 - mean_absolute_error: 0.0102 - val_loss: 3.3250e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 39/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5191e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 39: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 1.5191e-04 - mean_absolute_error: 0.0103 - val_loss: 1.3274e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 40/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5485e-04 - mean_absolute_error: 0.0106\n",
            "Epoch 40: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.5485e-04 - mean_absolute_error: 0.0106 - val_loss: 1.1231e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 41/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5236e-04 - mean_absolute_error: 0.0104\n",
            "Epoch 41: val_loss improved from 0.00003 to 0.00003, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 1.5236e-04 - mean_absolute_error: 0.0104 - val_loss: 2.5757e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 42/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4183e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 42: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 996ms/step - loss: 1.4183e-04 - mean_absolute_error: 0.0103 - val_loss: 3.0622e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 43/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5226e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 43: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.5226e-04 - mean_absolute_error: 0.0101 - val_loss: 2.9242e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 44/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4035e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 44: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.4035e-04 - mean_absolute_error: 0.0100 - val_loss: 4.4601e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 45/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.8213e-04 - mean_absolute_error: 0.0112\n",
            "Epoch 45: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.8213e-04 - mean_absolute_error: 0.0112 - val_loss: 4.5902e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 46/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2939e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 46: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.2939e-04 - mean_absolute_error: 0.0097 - val_loss: 4.4646e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 47/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.8574e-04 - mean_absolute_error: 0.0111\n",
            "Epoch 47: val_loss improved from 0.00003 to 0.00003, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 78s 967ms/step - loss: 1.8574e-04 - mean_absolute_error: 0.0111 - val_loss: 2.5108e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 48/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3855e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 48: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 79s 973ms/step - loss: 1.3855e-04 - mean_absolute_error: 0.0099 - val_loss: 2.5712e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 49/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3752e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 49: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 79s 978ms/step - loss: 1.3752e-04 - mean_absolute_error: 0.0100 - val_loss: 2.7527e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 50/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4376e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 50: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 79s 978ms/step - loss: 1.4376e-04 - mean_absolute_error: 0.0101 - val_loss: 6.6736e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 51/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2210e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 51: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 986ms/step - loss: 1.2210e-04 - mean_absolute_error: 0.0095 - val_loss: 2.5266e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 52/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3606e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 52: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 988ms/step - loss: 1.3606e-04 - mean_absolute_error: 0.0099 - val_loss: 6.4089e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 53/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5529e-04 - mean_absolute_error: 0.0109\n",
            "Epoch 53: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 986ms/step - loss: 1.5529e-04 - mean_absolute_error: 0.0109 - val_loss: 7.6886e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 54/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5059e-04 - mean_absolute_error: 0.0105\n",
            "Epoch 54: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 1.5059e-04 - mean_absolute_error: 0.0105 - val_loss: 8.5279e-05 - val_mean_absolute_error: 0.0082\n",
            "Epoch 55/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.6175e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 55: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 988ms/step - loss: 1.6175e-04 - mean_absolute_error: 0.0103 - val_loss: 1.2565e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 56/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.8378e-04 - mean_absolute_error: 0.0113\n",
            "Epoch 56: val_loss did not improve from 0.00003\n",
            "81/81 [==============================] - 80s 982ms/step - loss: 1.8378e-04 - mean_absolute_error: 0.0113 - val_loss: 2.6919e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 57/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2528e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 57: val_loss improved from 0.00003 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 79s 976ms/step - loss: 1.2528e-04 - mean_absolute_error: 0.0097 - val_loss: 2.4344e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 58/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2644e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 58: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 980ms/step - loss: 1.2644e-04 - mean_absolute_error: 0.0096 - val_loss: 8.5505e-05 - val_mean_absolute_error: 0.0087\n",
            "Epoch 59/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2834e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 59: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 985ms/step - loss: 1.2834e-04 - mean_absolute_error: 0.0100 - val_loss: 3.2173e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 60/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3626e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 60: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 1.3626e-04 - mean_absolute_error: 0.0101 - val_loss: 1.0125e-04 - val_mean_absolute_error: 0.0095\n",
            "Epoch 61/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2347e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 61: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 975ms/step - loss: 1.2347e-04 - mean_absolute_error: 0.0097 - val_loss: 6.6687e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 62/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3517e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 62: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 1.3517e-04 - mean_absolute_error: 0.0099 - val_loss: 2.7776e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 63/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4493e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 63: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 993ms/step - loss: 1.4493e-04 - mean_absolute_error: 0.0101 - val_loss: 1.0179e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 64/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1491e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 64: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.1491e-04 - mean_absolute_error: 0.0096 - val_loss: 4.8725e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 65/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2452e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 65: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 986ms/step - loss: 1.2452e-04 - mean_absolute_error: 0.0096 - val_loss: 3.7030e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 66/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2270e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 66: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 988ms/step - loss: 1.2270e-04 - mean_absolute_error: 0.0095 - val_loss: 2.7255e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 67/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2139e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 67: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 991ms/step - loss: 1.2139e-04 - mean_absolute_error: 0.0095 - val_loss: 2.7216e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 68/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3933e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 68: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 80s 982ms/step - loss: 1.3933e-04 - mean_absolute_error: 0.0099 - val_loss: 2.2808e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 69/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1281e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 69: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 1.1281e-04 - mean_absolute_error: 0.0092 - val_loss: 7.0751e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 70/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4186e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 70: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 991ms/step - loss: 1.4186e-04 - mean_absolute_error: 0.0101 - val_loss: 2.8474e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 71/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.4085e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 71: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 1.4085e-04 - mean_absolute_error: 0.0101 - val_loss: 6.5977e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 72/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1690e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 72: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 986ms/step - loss: 1.1690e-04 - mean_absolute_error: 0.0095 - val_loss: 8.1829e-05 - val_mean_absolute_error: 0.0078\n",
            "Epoch 73/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0921e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 73: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 977ms/step - loss: 1.0921e-04 - mean_absolute_error: 0.0092 - val_loss: 3.9692e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 74/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1834e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 74: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 980ms/step - loss: 1.1834e-04 - mean_absolute_error: 0.0094 - val_loss: 7.4139e-05 - val_mean_absolute_error: 0.0077\n",
            "Epoch 75/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1785e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 75: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 979ms/step - loss: 1.1785e-04 - mean_absolute_error: 0.0094 - val_loss: 3.0998e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 76/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0911e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 76: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 990ms/step - loss: 1.0911e-04 - mean_absolute_error: 0.0092 - val_loss: 2.7638e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 77/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0252e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 77: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 1.0252e-04 - mean_absolute_error: 0.0089 - val_loss: 2.3242e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 78/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0614e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 78: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 999ms/step - loss: 1.0614e-04 - mean_absolute_error: 0.0089 - val_loss: 3.1320e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 79/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2216e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 79: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 997ms/step - loss: 1.2216e-04 - mean_absolute_error: 0.0096 - val_loss: 5.2506e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 80/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1385e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 80: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 992ms/step - loss: 1.1385e-04 - mean_absolute_error: 0.0093 - val_loss: 3.8044e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 81/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2299e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 81: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 997ms/step - loss: 1.2299e-04 - mean_absolute_error: 0.0097 - val_loss: 5.0597e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 82/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1669e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 82: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.1669e-04 - mean_absolute_error: 0.0095 - val_loss: 2.5047e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 83/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1441e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 83: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 1.1441e-04 - mean_absolute_error: 0.0093 - val_loss: 2.7099e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 84/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2883e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 84: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 981ms/step - loss: 1.2883e-04 - mean_absolute_error: 0.0100 - val_loss: 5.9591e-05 - val_mean_absolute_error: 0.0075\n",
            "Epoch 85/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1243e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 85: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 1.1243e-04 - mean_absolute_error: 0.0093 - val_loss: 2.4729e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 86/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1928e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 86: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 1.1928e-04 - mean_absolute_error: 0.0096 - val_loss: 2.4312e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 87/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3130e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 87: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 986ms/step - loss: 1.3130e-04 - mean_absolute_error: 0.0098 - val_loss: 3.3088e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 88/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1111e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 88: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 1.1111e-04 - mean_absolute_error: 0.0094 - val_loss: 2.4441e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 89/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1739e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 89: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 1.1739e-04 - mean_absolute_error: 0.0092 - val_loss: 3.3665e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 90/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1870e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 90: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 989ms/step - loss: 1.1870e-04 - mean_absolute_error: 0.0094 - val_loss: 1.3098e-04 - val_mean_absolute_error: 0.0116\n",
            "Epoch 91/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3603e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 91: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 975ms/step - loss: 1.3603e-04 - mean_absolute_error: 0.0101 - val_loss: 2.3292e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 92/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0849e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 92: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 1.0849e-04 - mean_absolute_error: 0.0092 - val_loss: 2.8698e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 93/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1872e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 93: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 1.1872e-04 - mean_absolute_error: 0.0097 - val_loss: 2.9493e-04 - val_mean_absolute_error: 0.0154\n",
            "Epoch 94/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.5020e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 94: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 993ms/step - loss: 1.5020e-04 - mean_absolute_error: 0.0103 - val_loss: 2.7311e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 95/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0999e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 95: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 1.0999e-04 - mean_absolute_error: 0.0091 - val_loss: 2.9404e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 96/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2250e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 96: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 987ms/step - loss: 1.2250e-04 - mean_absolute_error: 0.0096 - val_loss: 3.7774e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 97/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1392e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 97: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 1.1392e-04 - mean_absolute_error: 0.0093 - val_loss: 1.0976e-04 - val_mean_absolute_error: 0.0100\n",
            "Epoch 98/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1545e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 98: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 992ms/step - loss: 1.1545e-04 - mean_absolute_error: 0.0094 - val_loss: 2.4211e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 99/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0937e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 99: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 1.0937e-04 - mean_absolute_error: 0.0090 - val_loss: 3.3946e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 100/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0994e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 100: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 992ms/step - loss: 1.0994e-04 - mean_absolute_error: 0.0090 - val_loss: 2.6897e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 101/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0826e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 101: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 1.0826e-04 - mean_absolute_error: 0.0090 - val_loss: 4.9272e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 102/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1579e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 102: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 80s 991ms/step - loss: 1.1579e-04 - mean_absolute_error: 0.0093 - val_loss: 2.0204e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 103/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0508e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 103: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 999ms/step - loss: 1.0508e-04 - mean_absolute_error: 0.0091 - val_loss: 3.8931e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 104/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.2004e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 104: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 1.2004e-04 - mean_absolute_error: 0.0096 - val_loss: 2.0434e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 105/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0927e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 105: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 996ms/step - loss: 1.0927e-04 - mean_absolute_error: 0.0092 - val_loss: 2.7399e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 106/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4515e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 106: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.4515e-05 - mean_absolute_error: 0.0087 - val_loss: 2.1397e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 107/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0346e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 107: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0346e-04 - mean_absolute_error: 0.0089 - val_loss: 2.1980e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 108/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0032e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 108: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0032e-04 - mean_absolute_error: 0.0088 - val_loss: 4.6937e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 109/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.8536e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 109: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.8536e-05 - mean_absolute_error: 0.0087 - val_loss: 3.3293e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 110/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.9138e-05 - mean_absolute_error: 0.0089\n",
            "Epoch 110: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.9138e-05 - mean_absolute_error: 0.0089 - val_loss: 5.3358e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 111/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0932e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 111: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 1.0932e-04 - mean_absolute_error: 0.0092 - val_loss: 2.3710e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 112/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1145e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 112: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.1145e-04 - mean_absolute_error: 0.0091 - val_loss: 2.6407e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 113/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1842e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 113: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.1842e-04 - mean_absolute_error: 0.0095 - val_loss: 3.2740e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 114/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0216e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 114: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0216e-04 - mean_absolute_error: 0.0088 - val_loss: 3.0220e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 115/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4304e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 115: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.4304e-05 - mean_absolute_error: 0.0087 - val_loss: 3.0342e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 116/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0849e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 116: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.0849e-04 - mean_absolute_error: 0.0091 - val_loss: 2.2010e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 117/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0042e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 117: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.0042e-04 - mean_absolute_error: 0.0087 - val_loss: 3.8818e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 118/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4562e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 118: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.4562e-05 - mean_absolute_error: 0.0087 - val_loss: 4.1814e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 119/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3857e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 119: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.3857e-05 - mean_absolute_error: 0.0087 - val_loss: 2.2014e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 120/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1625e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 120: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 992ms/step - loss: 9.1625e-05 - mean_absolute_error: 0.0087 - val_loss: 2.7490e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 121/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.2233e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 121: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.2233e-05 - mean_absolute_error: 0.0088 - val_loss: 2.1436e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 122/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0146e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 122: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.0146e-04 - mean_absolute_error: 0.0090 - val_loss: 4.1200e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 123/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0791e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 123: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0791e-04 - mean_absolute_error: 0.0090 - val_loss: 1.8348e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 124/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1104e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 124: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.1104e-04 - mean_absolute_error: 0.0093 - val_loss: 1.9714e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 125/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1140e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 125: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.1140e-04 - mean_absolute_error: 0.0092 - val_loss: 3.4685e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 126/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3298e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 126: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 9.3298e-05 - mean_absolute_error: 0.0087 - val_loss: 4.9812e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 127/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0851e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 127: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0851e-04 - mean_absolute_error: 0.0091 - val_loss: 3.6767e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 128/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.9843e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 128: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 993ms/step - loss: 9.9843e-05 - mean_absolute_error: 0.0088 - val_loss: 2.2021e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 129/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5607e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 129: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.5607e-05 - mean_absolute_error: 0.0086 - val_loss: 2.0215e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 130/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3524e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 130: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 992ms/step - loss: 9.3524e-05 - mean_absolute_error: 0.0085 - val_loss: 9.9053e-05 - val_mean_absolute_error: 0.0091\n",
            "Epoch 131/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0516e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 131: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 977ms/step - loss: 1.0516e-04 - mean_absolute_error: 0.0091 - val_loss: 4.5912e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 132/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.7237e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 132: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 991ms/step - loss: 9.7237e-05 - mean_absolute_error: 0.0087 - val_loss: 2.6671e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 133/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0204e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 133: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0204e-04 - mean_absolute_error: 0.0089 - val_loss: 3.3496e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 134/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1226e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 134: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 994ms/step - loss: 1.1226e-04 - mean_absolute_error: 0.0096 - val_loss: 2.2032e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 135/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3916e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 135: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 9.3916e-05 - mean_absolute_error: 0.0087 - val_loss: 3.0735e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 136/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5882e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 136: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 984ms/step - loss: 9.5882e-05 - mean_absolute_error: 0.0088 - val_loss: 2.6977e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 137/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.3275e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 137: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.3275e-04 - mean_absolute_error: 0.0103 - val_loss: 2.7388e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 138/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0856e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 138: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.0856e-04 - mean_absolute_error: 0.0093 - val_loss: 2.0634e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 139/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7782e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 139: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 992ms/step - loss: 8.7782e-05 - mean_absolute_error: 0.0085 - val_loss: 5.1168e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 140/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0720e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 140: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.0720e-05 - mean_absolute_error: 0.0086 - val_loss: 1.9674e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 141/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0510e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 141: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0510e-04 - mean_absolute_error: 0.0091 - val_loss: 1.9425e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 142/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0657e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 142: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0657e-04 - mean_absolute_error: 0.0091 - val_loss: 3.4049e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 143/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.9643e-05 - mean_absolute_error: 0.0090\n",
            "Epoch 143: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.9643e-05 - mean_absolute_error: 0.0090 - val_loss: 2.4093e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 144/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4766e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 144: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.4766e-05 - mean_absolute_error: 0.0087 - val_loss: 3.6648e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 145/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.6656e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 145: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 9.6656e-05 - mean_absolute_error: 0.0087 - val_loss: 3.1274e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 146/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.6499e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 146: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 979ms/step - loss: 9.6499e-05 - mean_absolute_error: 0.0088 - val_loss: 2.0765e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 147/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0763e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 147: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 996ms/step - loss: 1.0763e-04 - mean_absolute_error: 0.0091 - val_loss: 2.4216e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 148/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0377e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 148: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0377e-04 - mean_absolute_error: 0.0090 - val_loss: 2.5110e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 149/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5078e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 149: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.5078e-05 - mean_absolute_error: 0.0084 - val_loss: 2.1022e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 150/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0655e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 150: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.0655e-04 - mean_absolute_error: 0.0091 - val_loss: 2.1315e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 151/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.6810e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 151: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.6810e-05 - mean_absolute_error: 0.0088 - val_loss: 2.4528e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 152/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.2639e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 152: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.2639e-05 - mean_absolute_error: 0.0084 - val_loss: 1.9237e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 153/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1554e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 153: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.1554e-05 - mean_absolute_error: 0.0085 - val_loss: 2.3928e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 154/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0043e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 154: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.0043e-04 - mean_absolute_error: 0.0088 - val_loss: 2.0977e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 155/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0662e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 155: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0662e-04 - mean_absolute_error: 0.0093 - val_loss: 7.0937e-05 - val_mean_absolute_error: 0.0085\n",
            "Epoch 156/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5152e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 156: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.5152e-05 - mean_absolute_error: 0.0088 - val_loss: 1.8386e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 157/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.7326e-05 - mean_absolute_error: 0.0089\n",
            "Epoch 157: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 989ms/step - loss: 9.7326e-05 - mean_absolute_error: 0.0089 - val_loss: 2.3504e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 158/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.6410e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 158: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 80s 988ms/step - loss: 9.6410e-05 - mean_absolute_error: 0.0088 - val_loss: 1.7509e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 159/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3081e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 159: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 999ms/step - loss: 9.3081e-05 - mean_absolute_error: 0.0085 - val_loss: 2.1723e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 160/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0972e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 160: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 994ms/step - loss: 9.0972e-05 - mean_absolute_error: 0.0086 - val_loss: 2.5791e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 161/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0435e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 161: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.0435e-05 - mean_absolute_error: 0.0084 - val_loss: 1.9781e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 162/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1849e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 162: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.1849e-05 - mean_absolute_error: 0.0086 - val_loss: 2.4800e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 163/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.6505e-05 - mean_absolute_error: 0.0089\n",
            "Epoch 163: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.6505e-05 - mean_absolute_error: 0.0089 - val_loss: 9.5817e-05 - val_mean_absolute_error: 0.0093\n",
            "Epoch 164/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4855e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 164: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 998ms/step - loss: 9.4855e-05 - mean_absolute_error: 0.0086 - val_loss: 2.1419e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 165/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7342e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 165: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 8.7342e-05 - mean_absolute_error: 0.0084 - val_loss: 3.8756e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 166/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0312e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 166: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.0312e-05 - mean_absolute_error: 0.0086 - val_loss: 2.5508e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 167/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5282e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 167: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 993ms/step - loss: 8.5282e-05 - mean_absolute_error: 0.0084 - val_loss: 3.5059e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 168/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.9267e-05 - mean_absolute_error: 0.0089\n",
            "Epoch 168: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 994ms/step - loss: 9.9267e-05 - mean_absolute_error: 0.0089 - val_loss: 3.7014e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 169/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.1729e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 169: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 1.1729e-04 - mean_absolute_error: 0.0097 - val_loss: 5.2530e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 170/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4356e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 170: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 993ms/step - loss: 9.4356e-05 - mean_absolute_error: 0.0085 - val_loss: 2.3761e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 171/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7470e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 171: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1000ms/step - loss: 8.7470e-05 - mean_absolute_error: 0.0083 - val_loss: 2.2571e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 172/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.9272e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 172: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.9272e-05 - mean_absolute_error: 0.0088 - val_loss: 1.9924e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 173/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7573e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 173: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 8.7573e-05 - mean_absolute_error: 0.0083 - val_loss: 2.9784e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 174/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1143e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 174: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 999ms/step - loss: 9.1143e-05 - mean_absolute_error: 0.0087 - val_loss: 1.9803e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 175/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.9499e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 175: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 81s 997ms/step - loss: 7.9499e-05 - mean_absolute_error: 0.0081 - val_loss: 1.6664e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 176/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.9883e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 176: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 8.9883e-05 - mean_absolute_error: 0.0084 - val_loss: 1.9500e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 177/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.4854e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 177: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.4854e-05 - mean_absolute_error: 0.0083 - val_loss: 2.5075e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 178/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4865e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 178: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 998ms/step - loss: 9.4865e-05 - mean_absolute_error: 0.0086 - val_loss: 1.9258e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 179/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0534e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 179: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 990ms/step - loss: 1.0534e-04 - mean_absolute_error: 0.0093 - val_loss: 2.7800e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 180/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0651e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 180: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.0651e-05 - mean_absolute_error: 0.0088 - val_loss: 2.4371e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 181/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.8144e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 181: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.8144e-05 - mean_absolute_error: 0.0085 - val_loss: 2.7439e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 182/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5683e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 182: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.5683e-05 - mean_absolute_error: 0.0088 - val_loss: 2.5272e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 183/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.2780e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 183: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.2780e-05 - mean_absolute_error: 0.0084 - val_loss: 1.9442e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 184/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.4596e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 184: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 7.4596e-05 - mean_absolute_error: 0.0080 - val_loss: 1.9972e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 185/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.7233e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 185: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.7233e-05 - mean_absolute_error: 0.0087 - val_loss: 7.0396e-05 - val_mean_absolute_error: 0.0078\n",
            "Epoch 186/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0624e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 186: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0624e-04 - mean_absolute_error: 0.0092 - val_loss: 4.8813e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 187/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.9568e-05 - mean_absolute_error: 0.0090\n",
            "Epoch 187: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.9568e-05 - mean_absolute_error: 0.0090 - val_loss: 7.1885e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 188/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5013e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 188: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.5013e-05 - mean_absolute_error: 0.0087 - val_loss: 2.3033e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 189/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.8470e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 189: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.8470e-05 - mean_absolute_error: 0.0085 - val_loss: 1.9886e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 190/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6922e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 190: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.6922e-05 - mean_absolute_error: 0.0084 - val_loss: 1.9142e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 191/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3348e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 191: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 981ms/step - loss: 8.3348e-05 - mean_absolute_error: 0.0081 - val_loss: 2.8089e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 192/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.0824e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 192: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 8.0824e-05 - mean_absolute_error: 0.0081 - val_loss: 1.5695e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 193/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1075e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 193: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 982ms/step - loss: 9.1075e-05 - mean_absolute_error: 0.0086 - val_loss: 5.2653e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 194/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1583e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 194: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 78s 967ms/step - loss: 8.1583e-05 - mean_absolute_error: 0.0083 - val_loss: 2.7901e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 195/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.4926e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 195: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 970ms/step - loss: 8.4926e-05 - mean_absolute_error: 0.0083 - val_loss: 5.6438e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 196/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3400e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 196: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 979ms/step - loss: 8.3400e-05 - mean_absolute_error: 0.0083 - val_loss: 2.3647e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 197/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5141e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 197: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 975ms/step - loss: 8.5141e-05 - mean_absolute_error: 0.0082 - val_loss: 2.3843e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 198/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.2981e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 198: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 78s 969ms/step - loss: 9.2981e-05 - mean_absolute_error: 0.0086 - val_loss: 2.1729e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 199/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0413e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 199: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 974ms/step - loss: 9.0413e-05 - mean_absolute_error: 0.0085 - val_loss: 3.4193e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 200/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1566e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 200: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 79s 981ms/step - loss: 9.1566e-05 - mean_absolute_error: 0.0087 - val_loss: 1.8467e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 201/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.9881e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 201: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 7.9881e-05 - mean_absolute_error: 0.0081 - val_loss: 2.8298e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 202/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.0700e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 202: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 989ms/step - loss: 8.0700e-05 - mean_absolute_error: 0.0082 - val_loss: 2.3220e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 203/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1784e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 203: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 990ms/step - loss: 9.1784e-05 - mean_absolute_error: 0.0085 - val_loss: 1.0197e-04 - val_mean_absolute_error: 0.0082\n",
            "Epoch 204/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5751e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 204: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 996ms/step - loss: 9.5751e-05 - mean_absolute_error: 0.0088 - val_loss: 2.2877e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 205/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5168e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 205: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 990ms/step - loss: 8.5168e-05 - mean_absolute_error: 0.0082 - val_loss: 3.4590e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 206/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.8988e-05 - mean_absolute_error: 0.0089\n",
            "Epoch 206: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 994ms/step - loss: 9.8988e-05 - mean_absolute_error: 0.0089 - val_loss: 4.7913e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 207/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4168e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 207: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 990ms/step - loss: 9.4168e-05 - mean_absolute_error: 0.0088 - val_loss: 2.8181e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 208/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7988e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 208: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 997ms/step - loss: 8.7988e-05 - mean_absolute_error: 0.0086 - val_loss: 2.0583e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 209/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5028e-05 - mean_absolute_error: 0.0089\n",
            "Epoch 209: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.5028e-05 - mean_absolute_error: 0.0089 - val_loss: 1.8068e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 210/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1044e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 210: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.1044e-05 - mean_absolute_error: 0.0081 - val_loss: 2.3760e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 211/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6408e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 211: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 85s 1s/step - loss: 8.6408e-05 - mean_absolute_error: 0.0083 - val_loss: 2.3241e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 212/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5273e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 212: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 8.5273e-05 - mean_absolute_error: 0.0083 - val_loss: 1.9887e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 213/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1688e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 213: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 84s 1s/step - loss: 8.1688e-05 - mean_absolute_error: 0.0083 - val_loss: 1.6196e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 214/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1060e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 214: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.1060e-05 - mean_absolute_error: 0.0080 - val_loss: 2.1245e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 215/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3612e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 215: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.3612e-05 - mean_absolute_error: 0.0081 - val_loss: 1.7979e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 216/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2029e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 216: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.2029e-05 - mean_absolute_error: 0.0081 - val_loss: 1.6241e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 217/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3097e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 217: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 84s 1s/step - loss: 8.3097e-05 - mean_absolute_error: 0.0082 - val_loss: 1.6751e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 218/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3950e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 218: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.3950e-05 - mean_absolute_error: 0.0081 - val_loss: 1.8569e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 219/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.9500e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 219: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 7.9500e-05 - mean_absolute_error: 0.0082 - val_loss: 1.8248e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 220/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.2413e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 220: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 9.2413e-05 - mean_absolute_error: 0.0087 - val_loss: 1.8788e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 221/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3692e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 221: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 84s 1s/step - loss: 9.3692e-05 - mean_absolute_error: 0.0088 - val_loss: 2.6859e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 222/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0186e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 222: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 9.0186e-05 - mean_absolute_error: 0.0083 - val_loss: 2.3567e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 223/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3059e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 223: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.3059e-05 - mean_absolute_error: 0.0082 - val_loss: 1.9407e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 224/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5535e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 224: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.5535e-05 - mean_absolute_error: 0.0083 - val_loss: 5.0744e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 225/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0410e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 225: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 84s 1s/step - loss: 1.0410e-04 - mean_absolute_error: 0.0090 - val_loss: 2.1806e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 226/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6839e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 226: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.6839e-05 - mean_absolute_error: 0.0084 - val_loss: 2.9837e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 227/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1839e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 227: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 9.1839e-05 - mean_absolute_error: 0.0086 - val_loss: 6.1034e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 228/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1422e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 228: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.1422e-05 - mean_absolute_error: 0.0082 - val_loss: 1.9917e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 229/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6982e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 229: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 84s 1s/step - loss: 8.6982e-05 - mean_absolute_error: 0.0083 - val_loss: 2.8626e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 230/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.2499e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 230: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 84s 1s/step - loss: 9.2499e-05 - mean_absolute_error: 0.0087 - val_loss: 2.3840e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 231/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5538e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 231: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.5538e-05 - mean_absolute_error: 0.0084 - val_loss: 2.3981e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 232/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6493e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 232: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.6493e-05 - mean_absolute_error: 0.0084 - val_loss: 2.9704e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 233/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.8719e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 233: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 84s 1s/step - loss: 8.8719e-05 - mean_absolute_error: 0.0087 - val_loss: 1.6640e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 234/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2959e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 234: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.2959e-05 - mean_absolute_error: 0.0081 - val_loss: 2.0437e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 235/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0745e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 235: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.0745e-05 - mean_absolute_error: 0.0087 - val_loss: 2.1558e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 236/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7859e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 236: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.7859e-05 - mean_absolute_error: 0.0088 - val_loss: 2.4645e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 237/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.9532e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 237: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 7.9532e-05 - mean_absolute_error: 0.0080 - val_loss: 2.6005e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 238/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3571e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 238: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.3571e-05 - mean_absolute_error: 0.0087 - val_loss: 3.3058e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 239/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5218e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 239: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.5218e-05 - mean_absolute_error: 0.0088 - val_loss: 3.6503e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 240/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.4495e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 240: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 8.4495e-05 - mean_absolute_error: 0.0084 - val_loss: 1.5843e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 241/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.7243e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 241: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 983ms/step - loss: 7.7243e-05 - mean_absolute_error: 0.0080 - val_loss: 2.2516e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 242/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0463e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 242: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 993ms/step - loss: 9.0463e-05 - mean_absolute_error: 0.0084 - val_loss: 2.7339e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 243/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0891e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 243: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 991ms/step - loss: 1.0891e-04 - mean_absolute_error: 0.0093 - val_loss: 1.4081e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 244/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0596e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 244: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 1.0596e-04 - mean_absolute_error: 0.0093 - val_loss: 1.9931e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 245/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3456e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 245: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 80s 990ms/step - loss: 8.3456e-05 - mean_absolute_error: 0.0082 - val_loss: 2.3759e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 246/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5604e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 246: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 996ms/step - loss: 8.5604e-05 - mean_absolute_error: 0.0083 - val_loss: 2.5390e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 247/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.7503e-05 - mean_absolute_error: 0.0089\n",
            "Epoch 247: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 9.7503e-05 - mean_absolute_error: 0.0089 - val_loss: 8.1534e-05 - val_mean_absolute_error: 0.0101\n",
            "Epoch 248/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.9973e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 248: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1s/step - loss: 8.9973e-05 - mean_absolute_error: 0.0086 - val_loss: 2.3269e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 249/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.5579e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 249: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 82s 1s/step - loss: 7.5579e-05 - mean_absolute_error: 0.0080 - val_loss: 1.6845e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 250/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.5726e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 250: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 999ms/step - loss: 7.5726e-05 - mean_absolute_error: 0.0080 - val_loss: 3.5352e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 251/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.0875e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 251: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.0875e-05 - mean_absolute_error: 0.0081 - val_loss: 1.5551e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 252/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.5100e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 252: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 1000ms/step - loss: 7.5100e-05 - mean_absolute_error: 0.0080 - val_loss: 2.2028e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 253/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.7838e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 253: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 999ms/step - loss: 7.7838e-05 - mean_absolute_error: 0.0080 - val_loss: 2.3008e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 254/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6695e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 254: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.6695e-05 - mean_absolute_error: 0.0084 - val_loss: 5.2073e-05 - val_mean_absolute_error: 0.0067\n",
            "Epoch 255/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5653e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 255: val_loss improved from 0.00002 to 0.00002, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.5653e-05 - mean_absolute_error: 0.0084 - val_loss: 1.5176e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 256/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.4537e-05 - mean_absolute_error: 0.0088\n",
            "Epoch 256: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 9.4537e-05 - mean_absolute_error: 0.0088 - val_loss: 1.8380e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 257/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.8515e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 257: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 995ms/step - loss: 7.8515e-05 - mean_absolute_error: 0.0083 - val_loss: 2.0160e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 258/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2141e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 258: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 81s 994ms/step - loss: 8.2141e-05 - mean_absolute_error: 0.0081 - val_loss: 2.0754e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 259/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6716e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 259: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.6716e-05 - mean_absolute_error: 0.0083 - val_loss: 2.3357e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 260/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6646e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 260: val_loss did not improve from 0.00002\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.6646e-05 - mean_absolute_error: 0.0085 - val_loss: 4.5430e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 261/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2913e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 261: val_loss improved from 0.00002 to 0.00001, saving model to results/2022-04-01_QQQ-sh-1-sc-1-sbd-0-huber_loss-<keras.optimizer_v2.adam.Adam object at 0x7f1440fcfc10>-LSTM-seq-50-step-1-layers-3-units-256.h5\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.2913e-05 - mean_absolute_error: 0.0082 - val_loss: 1.4421e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 262/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.6991e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 262: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 82s 1s/step - loss: 7.6991e-05 - mean_absolute_error: 0.0080 - val_loss: 2.5512e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 263/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7787e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 263: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 81s 1s/step - loss: 8.7787e-05 - mean_absolute_error: 0.0083 - val_loss: 4.4655e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 264/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.9456e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 264: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 83s 1s/step - loss: 8.9456e-05 - mean_absolute_error: 0.0084 - val_loss: 4.2719e-05 - val_mean_absolute_error: 0.0069\n",
            "Epoch 265/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2348e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 265: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 82s 1s/step - loss: 8.2348e-05 - mean_absolute_error: 0.0082 - val_loss: 1.6788e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 266/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.3332e-05 - mean_absolute_error: 0.0087\n",
            "Epoch 266: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 81s 1000ms/step - loss: 9.3332e-05 - mean_absolute_error: 0.0087 - val_loss: 2.2503e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 267/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.8072e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 267: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 81s 1000ms/step - loss: 8.8072e-05 - mean_absolute_error: 0.0083 - val_loss: 2.5610e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 268/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.8217e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 268: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 82s 1s/step - loss: 7.8217e-05 - mean_absolute_error: 0.0081 - val_loss: 1.5032e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 269/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.0763e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 269: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 84s 1s/step - loss: 9.0763e-05 - mean_absolute_error: 0.0086 - val_loss: 2.3998e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 270/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.8972e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 270: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 84s 1s/step - loss: 7.8972e-05 - mean_absolute_error: 0.0083 - val_loss: 1.8728e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 271/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7092e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 271: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 8.7092e-05 - mean_absolute_error: 0.0083 - val_loss: 2.1748e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 272/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.4733e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 272: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 8.4733e-05 - mean_absolute_error: 0.0083 - val_loss: 1.5090e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 273/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6616e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 273: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.6616e-05 - mean_absolute_error: 0.0084 - val_loss: 1.9088e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 274/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.1370e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 274: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 7.1370e-05 - mean_absolute_error: 0.0078 - val_loss: 2.1755e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 275/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1518e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 275: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 88s 1s/step - loss: 8.1518e-05 - mean_absolute_error: 0.0083 - val_loss: 2.2125e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 276/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2708e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 276: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 91s 1s/step - loss: 8.2708e-05 - mean_absolute_error: 0.0083 - val_loss: 2.0435e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 277/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6401e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 277: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 90s 1s/step - loss: 8.6401e-05 - mean_absolute_error: 0.0082 - val_loss: 2.0075e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 278/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.0487e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 278: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.0487e-05 - mean_absolute_error: 0.0082 - val_loss: 1.5411e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 279/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.3194e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 279: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.3194e-05 - mean_absolute_error: 0.0082 - val_loss: 2.0782e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 280/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.8851e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 280: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 7.8851e-05 - mean_absolute_error: 0.0080 - val_loss: 1.6300e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 281/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.6396e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 281: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 84s 1s/step - loss: 7.6396e-05 - mean_absolute_error: 0.0079 - val_loss: 1.7049e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 282/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1663e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 282: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 84s 1s/step - loss: 8.1663e-05 - mean_absolute_error: 0.0082 - val_loss: 1.9142e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 283/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.5965e-05 - mean_absolute_error: 0.0092\n",
            "Epoch 283: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 9.5965e-05 - mean_absolute_error: 0.0092 - val_loss: 1.8683e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 284/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.0285e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 284: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 8.0285e-05 - mean_absolute_error: 0.0080 - val_loss: 2.8749e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 285/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.1384e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 285: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 8.1384e-05 - mean_absolute_error: 0.0082 - val_loss: 2.8800e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 286/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.7147e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 286: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.7147e-05 - mean_absolute_error: 0.0085 - val_loss: 2.5824e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 287/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.9928e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 287: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 89s 1s/step - loss: 8.9928e-05 - mean_absolute_error: 0.0086 - val_loss: 1.5064e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 288/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.9047e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 288: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 88s 1s/step - loss: 7.9047e-05 - mean_absolute_error: 0.0080 - val_loss: 1.5344e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 289/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2843e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 289: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.2843e-05 - mean_absolute_error: 0.0082 - val_loss: 2.0467e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 290/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.6119e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 290: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.6119e-05 - mean_absolute_error: 0.0084 - val_loss: 2.1553e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 291/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.5579e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 291: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 7.5579e-05 - mean_absolute_error: 0.0078 - val_loss: 1.8464e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 292/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.9863e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 292: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 88s 1s/step - loss: 7.9863e-05 - mean_absolute_error: 0.0081 - val_loss: 1.4509e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 293/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 1.0076e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 293: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 84s 1s/step - loss: 1.0076e-04 - mean_absolute_error: 0.0090 - val_loss: 3.5427e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 294/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.4384e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 294: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 89s 1s/step - loss: 8.4384e-05 - mean_absolute_error: 0.0083 - val_loss: 1.8110e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 295/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 9.1191e-05 - mean_absolute_error: 0.0085\n",
            "Epoch 295: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 84s 1s/step - loss: 9.1191e-05 - mean_absolute_error: 0.0085 - val_loss: 1.8035e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 296/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.0022e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 296: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.0022e-05 - mean_absolute_error: 0.0079 - val_loss: 2.5883e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 297/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.2407e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 297: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 8.2407e-05 - mean_absolute_error: 0.0081 - val_loss: 2.1496e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 298/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 7.1261e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 298: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 7.1261e-05 - mean_absolute_error: 0.0079 - val_loss: 1.6248e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 299/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.0284e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 299: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 86s 1s/step - loss: 8.0284e-05 - mean_absolute_error: 0.0081 - val_loss: 1.5510e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 300/300\n",
            "81/81 [==============================] - ETA: 0s - loss: 8.5853e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 300: val_loss did not improve from 0.00001\n",
            "81/81 [==============================] - 85s 1s/step - loss: 8.5853e-05 - mean_absolute_error: 0.0081 - val_loss: 2.7283e-05 - val_mean_absolute_error: 0.0045\n"
          ]
        }
      ],
      "source": [
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")\n",
        "\n",
        "\n",
        "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
        "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
        "                feature_columns=FEATURE_COLUMNS)\n",
        "\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "\n",
        "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER)\n",
        "\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                   \n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BfiVX3X6GEO9"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23PASIx8GGl1"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "\n",
        "if SCALE:\n",
        "    mean_absolute_error = data[\"column_scaler\"][\"close\"].inverse_transform([[mae]])[0][0]\n",
        "else:\n",
        "    mean_absolute_error = mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzYkKG8QGHWO"
      },
      "outputs": [],
      "source": [
        "\n",
        "final_df = get_final_df(model, data)\n",
        "\n",
        "future_price = predict(model, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gslssJPZGQqR"
      },
      "outputs": [],
      "source": [
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3UfELO0FyRU"
      },
      "outputs": [],
      "source": [
        "#@title \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graph(test_df):\n",
        "    plt.plot(test_df[f'true_close_{LOOKUP_STEP}'], c='b')\n",
        "    plt.plot(test_df[f'close_{LOOKUP_STEP}'], c='r')\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWW863F8Gl8w"
      },
      "outputs": [],
      "source": [
        "plot_graph(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpHEfjihEpnm"
      },
      "outputs": [],
      "source": [
        "def get_account():\n",
        "  r = requests.get(ACCOUNT_URL , headers=HEADERS)\n",
        "  return json.loads(r.content)\n",
        "\n",
        "cash = float(get_account()['cash'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjSvQgTWw2qm"
      },
      "outputs": [],
      "source": [
        "def create_order(symbol , qty , side , type , time_in_force):\n",
        "  data= {\"symbol\": symbol , \"qty\": qty , \"side\": side , \"type\": type ,\"time_in_force\": time_in_force}\n",
        "  r = requests.post(ORDERS_URL ,json=data, headers=HEADERS)\n",
        "  return json.loads(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IzyG7LHw5UN"
      },
      "outputs": [],
      "source": [
        "def get_position(symbol ):\n",
        "  data= {\"symbol\": symbol }\n",
        "  r = requests.get(POSITIONS_URL,json=data, headers=HEADERS)\n",
        "  return json.loads(r.content)\n",
        "\n",
        "res = get_position(ticker)\n",
        "\n",
        "shares=0\n",
        "avg_price=0\n",
        "lastday_price=0\n",
        "if len(res) :\n",
        "    print('ok' , res)\n",
        "    shares = float(res[0]['qty'])\n",
        "    avg_price =float(res[0]['avg_entry_price'])\n",
        "    lastday_price = float(res[0]['lastday_price'])\n",
        "\n",
        "\n",
        "else:\n",
        "  print('no position')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F77PsAX0tYC2"
      },
      "outputs": [],
      "source": [
        "print(lastday_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL-fkZSow7k2"
      },
      "outputs": [],
      "source": [
        "STRONG_BUY = 'strong buy'\n",
        "BUY = 'buy'\n",
        "NEUTRAL = 'neutral'\n",
        "SELL= 'sell'\n",
        "STRONG_SELL = 'strong sell'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krv1AN-Bw9PR"
      },
      "outputs": [],
      "source": [
        "today = datetime.today().strftime('%d/%m/%Y')\n",
        "today_price = si.get_data(\"QQQ\" )['close'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ipqXYjF3w-sI"
      },
      "outputs": [],
      "source": [
        "def signal(preditct_price , actual_price):\n",
        "  difference =  ((preditct_price - actual_price) / (actual_price)) * 100\n",
        "  print('Difference :' , difference)\n",
        "  if difference >=2:\n",
        "    return STRONG_BUY\n",
        "  \n",
        "  elif difference>=0.5 and difference < 2:\n",
        "    return BUY\n",
        "\n",
        "  elif difference< 0.5 and difference >-0.5:\n",
        "    return NEUTRAL\n",
        "\n",
        "  elif difference <= -0.5 and difference > -2:\n",
        "    return SELL\n",
        "\n",
        "  elif difference <= -2:\n",
        "    return STRONG_SELL\n",
        "\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhwgEUNHxIaX"
      },
      "outputs": [],
      "source": [
        "SIGNAL= signal(future_price, today_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5lnhqOWy57w"
      },
      "outputs": [],
      "source": [
        "def trade(SIGNAL, cash , shares , lastday_price ):\n",
        " \n",
        "  if SIGNAL == STRONG_BUY:\n",
        "    cash *= 0.5\n",
        "    total_share = int(cash/lastday_price)\n",
        "    create_order(ticker , total_share , \"buy\", \"market\", \"gtc\")\n",
        "    print( 'Singal :', SIGNAL )\n",
        "    print('shares will buy ',total_share  )\n",
        "\n",
        "  elif SIGNAL == BUY:\n",
        "    cash *= 0.2\n",
        "    total_share = int(cash/lastday_price)\n",
        "    create_order(ticker, total_share , \"buy\", \"market\", \"gtc\")\n",
        "    print( 'Singal :', SIGNAL )\n",
        "    print('shares will buy',total_share )\n",
        "\n",
        "  elif SIGNAL == NEUTRAL:\n",
        "    print( 'Singal :', SIGNAL )\n",
        "\n",
        "\n",
        "  elif SIGNAL == SELL:\n",
        "    shares *= 0.5\n",
        "    shares = int(shares)\n",
        "    create_order(ticker, shares , \"sell\", \"market\", \"gtc\")\n",
        "\n",
        "  elif SIGNAL == STRONG_SELL:\n",
        "    shares = int(shares)\n",
        "    create_order(ticker, shares , \"sell\", \"market\", \"gtc\")\n",
        "  \n",
        "  else:\n",
        "    print('NO actions')\n",
        "\n",
        "\n",
        "trade(SIGNAL, cash , shares , today_price)\n",
        "print('Signal : ', SIGNAL)\n",
        "print('Shares are holding', shares)\n",
        "print('Cash in hand', cash)\n",
        "print('Average position' , avg_price)\n",
        "print('Predict price' , future_price)\n",
        "print('today_price', today_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6oYEDBIBI5r"
      },
      "outputs": [],
      "source": [
        "\n",
        "trade(SIGNAL, cash , shares , today_price)\n",
        "print('Signal : ', SIGNAL)\n",
        "print('Shares are holding', shares)\n",
        "print('Cash in hand', cash)\n",
        "print('Average position' , avg_price)\n",
        "print('Predict price' , future_price)\n",
        "print('today_price', today_price)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "fyp(firm).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
